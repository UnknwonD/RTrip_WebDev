from typing import List, Dict
import torch
from torch import nn
import torch.nn.functional as F
from torch_geometric.nn import HeteroConv, SAGEConv
from sklearn.preprocessing import MinMaxScaler
from torch_geometric.data import HeteroData
from typing import Dict, List

import pickle
from datetime import datetime
import pandas as pd
import numpy as np

# app.py ì•ˆì—ì„œ í…œí”Œë¦¿ì— ë„˜ê²¨ì¤„ ë¦¬ìŠ¤íŠ¸
user_feature_keys = [
    'GENDER', 'EDU_NM', 'EDU_FNSH_SE', 'MARR_STTS', 'JOB_NM', 'HOUSE_INCOME',
    'TRAVEL_TERM', 'TRAVEL_LIKE_SIDO_1', 'TRAVEL_LIKE_SIDO_2', 'TRAVEL_LIKE_SIDO_3',
    'AGE_GRP', 'FAMILY_MEMB', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM',
    'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4',
    'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',
    'TRAVEL_MOTIVE_1', 'TRAVEL_MOTIVE_2', 'INCOME'
]

travel_feature_keys = [
    'LODGOUT_COST', 'ACTIVITY_COST', 'TOTAL_COST', 'DURATION', 'PURPOSE_1',
    'PURPOSE_10', 'PURPOSE_11', 'PURPOSE_12', 'PURPOSE_13', 'PURPOSE_2',
    'PURPOSE_21', 'PURPOSE_22', 'PURPOSE_23', 'PURPOSE_24', 'PURPOSE_25',
    'PURPOSE_26', 'PURPOSE_27', 'PURPOSE_28', 'PURPOSE_3', 'PURPOSE_4',
    'PURPOSE_5', 'PURPOSE_6', 'PURPOSE_7', 'PURPOSE_8', 'PURPOSE_9',
    'MVMN_NM_ENC', 'age_ENC', 'whowith_ENC', 'mission_ENC'
]

# ë‹¤ì‹œ ë³€ìˆ˜ ì •ì˜ (í™˜ê²½ ë¦¬ì…‹ë¨)
# purpose_options = [
#     (1, "ì‡¼í•‘"), (2, "í…Œë§ˆíŒŒí¬, ë†€ì´ì‹œì„¤, ë™/ì‹ë¬¼ì› ë°©ë¬¸"), (3, "ì—­ì‚¬ ìœ ì ì§€ ë°©ë¬¸"),
#     (4, "ì‹œí‹°íˆ¬ì–´"), (5, "ì•¼ì™¸ ìŠ¤í¬ì¸ , ë ˆí¬ì¸  í™œë™"), (6, "ì§€ì—­ ë¬¸í™”ì˜ˆìˆ /ê³µì—°/ì „ì‹œì‹œì„¤ ê´€ëŒ"),
#     (7, "ìœ í¥/ì˜¤ë½(ë‚˜ì´íŠ¸ë¼ì´í”„)"), (8, "ìº í•‘"), (9, "ì§€ì—­ ì¶•ì œ/ì´ë²¤íŠ¸ ì°¸ê°€"),
#     (10, "ì˜¨ì²œ/ìŠ¤íŒŒ"), (11, "êµìœ¡/ì²´í—˜ í”„ë¡œê·¸ë¨ ì°¸ê°€"), (12, "ë“œë¼ë§ˆ ì´¬ì˜ì§€ ë°©ë¬¸"),
#     (13, "ì¢…êµ/ì„±ì§€ ìˆœë¡€"), (21, "Well-ness ì—¬í–‰"), (22, "SNS ì¸ìƒìƒ· ì—¬í–‰"),
#     (23, "í˜¸ìº‰ìŠ¤ ì—¬í–‰"), (24, "ì‹ ê·œ ì—¬í–‰ì§€ ë°œêµ´"), (25, "ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì—¬í–‰"),
#     (26, "ì¸í”Œë£¨ì–¸ì„œ ë”°ë¼í•˜ê¸° ì—¬í–‰"), (27, "ì¹œí™˜ê²½ ì—¬í–‰(í”Œë¡œê¹… ì—¬í–‰)"), (28, "ë“±ë°˜ ì—¬í–‰")
# ]

purpose_options =[
    (1, "ğŸ›ï¸ ì‡¼í•‘ & íŠ¸ë Œë“œ íƒë°©"), (2, "ğŸ›ï¸ ë¬¸í™”Â·ì˜ˆìˆ Â·ì—­ì‚¬ ì²´í—˜"), (3, "ğŸ¢ í…Œë§ˆíŒŒí¬ & ë†€ì´ì‹œì„¤"), (4, "ğŸ™ï¸ ë„ì‹¬ ì—¬í–‰ & íœ´ì‹" ),
    (5, "ğŸ•ï¸ ì•„ì›ƒë„ì–´ & ì•¡í‹°ë¹„í‹°"), (6, "â™¨ï¸ ì˜¨ì²œ & íë§ ì—¬í–‰"), (7, "ğŸ“¸ SNS í•«í”Œ & ì¸ìƒìƒ·"), (8, "âœ¨ ì‹ ê·œ & ë¯¸ê°œì²™ ì§€ì—­ íƒë°©"),
    (9, "ğŸŒ¿ ì¹œí™˜ê²½ & ì§€ì†ê°€ëŠ¥í•œ ì—¬í–‰")
]

# ì´ë¦„ ë³€ê²½
movement_options = [
    (1, "ìê°€ìš©"),
    (2, "ëŒ€ì¤‘êµí†µ"),
    (3, "ê¸°íƒ€ ì´ë™ìˆ˜ë‹¨")
]

# ë‹¤ì‹œ ë³€ìˆ˜ ì •ì˜ (í™˜ê²½ ë¦¬ì…‹ë¨)
# whowith_options = [
#     ("ì»¤í”Œ (2ì¸ ì—¬í–‰)", "ì»¤í”Œ"), ("ë‚˜í™€ë¡œ ì—¬í–‰", "ë‚˜í™€ë¡œ ì—¬í–‰"),
#     ("ìë…€ë™ë°˜", "ìë…€ë™ë°˜"), ("ë¶€ë¶€", "ë¶€ë¶€"), ("3ì¸ ì´ìƒ ì¹œêµ¬", "3ì¸ ì´ìƒ ì¹œêµ¬"),
#     ("ë¶€ëª¨ ë™ë°˜", "ë¶€ëª¨ ë™ë°˜"), ("3ëŒ€ ë™ë°˜ ì—¬í–‰", "3ëŒ€ ë™ë°˜ ì—¬í–‰")
# ]

# whowith_options = [
#     ("ë‹¨ë…ì—¬í–‰", "ë‚˜í™€ë¡œ ì—¬í–‰"),
#     ("2ì¸ì—¬í–‰", "ì»¤í”Œ"),
#     ("2ì¸ì—¬í–‰", "ë¶€ë¶€"),
#     ("ê°€ì¡±ì—¬í–‰" , "ìë…€ë™ë°˜"),
#     ("ê°€ì¡±ì—¬í–‰", "ë¶€ëª¨ ë™ë°˜"),
#     ("ê°€ì¡±ì—¬í–‰", "3ëŒ€ ë™ë°˜ ì—¬í–‰"),
#     ("ì¹œêµ¬/ì§€ì¸ ì—¬í–‰", "3ì¸ ì´ìƒ ì¹œêµ¬"),
#     ("ê¸°íƒ€", "ê¸°íƒ€")
# ]

whowith_options = [
    ("ë‹¨ë…ì—¬í–‰", ["ë‚˜í™€ë¡œ ì—¬í–‰"]),
    ("2ì¸ì—¬í–‰", ["ì»¤í”Œ", "ë¶€ë¶€"]),
    ("ê°€ì¡±ì—¬í–‰", ["ìë…€ë™ë°˜", "ë¶€ëª¨ ë™ë°˜", "3ëŒ€ ë™ë°˜ ì—¬í–‰"]),
    ("ì¹œêµ¬/ì§€ì¸ ì—¬í–‰", ["3ì¸ ì´ìƒ ì¹œêµ¬"]),
    ("ê¸°íƒ€", ["ê¸°íƒ€"])
]

class PpiKkoTwistGNN(nn.Module):  # ì‚ì‚ê¼¬ëŠ” GNN
    def __init__(self, metadata, user_input_dim, travel_input_dim, hidden_dim=128, num_layers=8):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers

        # Input Projections
        self.input_proj = nn.ModuleDict({
            'user': nn.Linear(user_input_dim, hidden_dim),
            'travel': nn.Linear(travel_input_dim, hidden_dim),
            'visit_area': nn.Identity()
        })

        # Deep HeteroConv Layers
        self.convs = nn.ModuleList([
            HeteroConv(
                {etype: SAGEConv((-1, -1), hidden_dim) for etype in metadata[1]},
                aggr='sum'
            ) for _ in range(num_layers)
        ])
        self.norms = nn.ModuleList([
            nn.ModuleDict({ntype: nn.LayerNorm(hidden_dim) for ntype in metadata[0]})
            for _ in range(num_layers)
        ])

        self.dropout = nn.Dropout(0.35)

        # Multi-Expert System (location / preference / category)
        self.expert_location = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1)
        )
        self.expert_preference = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1)
        )
        self.expert_category = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1)
        )

        # Multihead Attention Gating: attend across experts
        self.attn_gate = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, batch_first=True)
        self.attn_query = nn.Parameter(torch.randn(1, hidden_dim))

        self.final_proj = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, 1)
        )

    def forward(self, x_dict, edge_index_dict, feedback_mask=None):
        # 1. Input projection
        x_dict = {k: self.input_proj[k](v) if k in self.input_proj else v for k, v in x_dict.items()}

        # 2. Deep GNN layers with residuals
        for i in range(self.num_layers):
            h_dict = self.convs[i](x_dict, edge_index_dict)
            h_dict = {
                k: self.dropout(F.relu(self.norms[i][k](v))) + x_dict[k]
                for k, v in h_dict.items() if k in x_dict
            }
            x_dict = h_dict

        h_visit = x_dict['visit_area']  # [num_nodes, hidden_dim]

        # 3. Expert Predictions
        loc = self.expert_location(h_visit)         # [N, 1]
        pref = self.expert_preference(h_visit)      # [N, 1]
        cat = self.expert_category(h_visit)         # [N, 1]
        experts = torch.cat([loc, pref, cat], dim=1).unsqueeze(1)  # [N, 1, 3]

        # 4. Multi-head Attention Gating
        q = self.attn_query.expand(h_visit.size(0), -1).unsqueeze(1)  # [N, 1, H]
        attn_out, _ = self.attn_gate(q, h_visit.unsqueeze(1), h_visit.unsqueeze(1))  # [N, 1, H]
        final_score = self.final_proj(attn_out.squeeze(1)).squeeze(-1)  # [N]

        if feedback_mask is not None:
            final_score = final_score + feedback_mask

        return final_score

class LiteTwistGNN(nn.Module):
    def __init__(self, metadata, user_input_dim, travel_input_dim, hidden_dim=64, num_layers=2):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers

        # Input projection
        self.input_proj = nn.ModuleDict({
            'user': nn.Linear(user_input_dim, hidden_dim),
            'travel': nn.Linear(travel_input_dim, hidden_dim),
            'visit_area': nn.Identity()  # zero-init at inference
        })

        # Lightweight HeteroConv stack (2 layers)
        self.convs = nn.ModuleList([
            HeteroConv(
                {etype: SAGEConv((-1, -1), hidden_dim) for etype in metadata[1]},
                aggr='sum'
            ) for _ in range(num_layers)
        ])
        self.norms = nn.ModuleList([
            nn.ModuleDict({ntype: nn.LayerNorm(hidden_dim) for ntype in metadata[0]})
            for _ in range(num_layers)
        ])
        self.dropout = nn.Dropout(0.25)

        # Unified MLP scorer
        self.mlp = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, 1)
        )

    def forward(self, x_dict, edge_index_dict, feedback_mask=None):
        # Projection
        x_dict = {
            k: self.input_proj[k](v) if k in self.input_proj else v
            for k, v in x_dict.items()
        }

        # GNN Layers
        for i in range(self.num_layers):
            h_dict = self.convs[i](x_dict, edge_index_dict)
            h_dict = {
                k: self.dropout(F.relu(self.norms[i][k](v))) + x_dict[k]
                for k, v in h_dict.items() if k in x_dict
            }
            x_dict = h_dict

        h_visit = x_dict['visit_area']
        out = self.mlp(h_visit).squeeze(-1)

        if feedback_mask is not None:
            out = out + feedback_mask

        return out

# 2. ì¶”ì²œ ì¶”ë¡  í•¨ìˆ˜
def recommend_from_input(model: nn.Module,
                         user_input_df,  # shape: (1, 25)
                         travel_input_df,  # shape: (1, 29)
                         base_data: HeteroData,
                         visit_area_id_map: Dict[str, int],
                         topk: int = 5) -> List[Dict[str, float]]:
    
    # 1. tensor ë³€í™˜
    user_tensor = torch.tensor(user_input_df.values, dtype=torch.float)
    travel_tensor = torch.tensor(travel_input_df.values, dtype=torch.float)

    # 2. base_data ë³µì‚¬ ë° ì…ë ¥ ì¶”ê°€
    data = base_data[3].clone()
    data['user'].x = torch.cat([data['user'].x, user_tensor], dim=0)
    data['travel'].x = torch.cat([data['travel'].x, travel_tensor], dim=0)

    uid = data['user'].x.size(0) - 1
    tid = data['travel'].x.size(0) - 1

    # 3. ì—£ì§€ ì—°ê²° (ë‹¨ë°©í–¥ + ì—­ë°©í–¥)
    data[('user', 'traveled', 'travel')].edge_index = torch.cat([
        data[('user', 'traveled', 'travel')].edge_index,
        torch.tensor([[uid], [tid]], dtype=torch.long)
    ], dim=1)

    data[('travel', 'traveled_by', 'user')].edge_index = torch.cat([
        data[('travel', 'traveled_by', 'user')].edge_index,
        torch.tensor([[tid], [uid]], dtype=torch.long)
    ], dim=1)

    # 4. ì¶”ë¡ 
    with torch.no_grad():
        scores = model(data.x_dict, data.edge_index_dict)
        k = min(topk, scores.size(0))
        topk_result = torch.topk(scores, k)
        indices = topk_result.indices.tolist()
        values = topk_result.values.tolist()

    # 5. index â†’ visit_area_id ë³€í™˜
    index_to_id = {v: k for k, v in visit_area_id_map.items()}
    results = []

    for i, v in zip(indices, values):
        va_id = index_to_id.get(i, f"UNKNOWN_{i}")
        results.append({
            "visit_area_id": va_id,
            "score": round(float(v), 4)
        })

    return results

def preprocess_gnn(user_json: dict, travel_input_raw: dict):
    # 1. USER ì²˜ë¦¬
    user_input = {}
    for key in user_feature_keys:
        val = user_json.get(key, 0)
        user_input[key] = float(val) if str(val).isdigit() else 0

    # 2. TRAVEL ì²˜ë¦¬
    travel_input = {k: 0.0 for k in travel_feature_keys}
    
    # for k in ['LODGOUT_COST', 'ACTIVITY_COST', 'TOTAL_COST']:
    #     raw_val = travel_input_raw.get(k, "0")
    #     travel_input[k] = float(raw_val) * 10000

    
    # ì—¬í–‰ ê¸°ê°„ â†’ DURATION ê³„ì‚°
    date_range = travel_input_raw.get('date_range', '')
    try:
        start_str, end_str = [d.strip() for d in date_range.split('-')]
        start = datetime.strptime(start_str, "%Y-%m-%d")
        end = datetime.strptime(end_str, "%Y-%m-%d")
        travel_input['DURATION'] = max((end - start).days, 1)
    except:
        travel_input['DURATION'] = 1.0

    scaler = pickle.load(open('./pickle/cost_scaler.pkl', 'rb'))
    # 1. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ëª©ë¡
    num_cols = ["LODGOUT_COST", "ACTIVITY_COST", "TOTAL_COST", "DURATION"]

    # 2. travel_input_raw = ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¬¸ìì—´ ë”•ì…”ë„ˆë¦¬ (ex. from Flask form)
    #    ì˜ˆì‹œ: {'LODGOUT_COST': '2.5', 'DURATION': '3', ...}
    #    â†’ ê°’ì€ floatìœ¼ë¡œ, ì˜ˆì‚°ì€ Ã—10000 ì²˜ë¦¬
    input_vals = []
    for col in num_cols:
        val = float(travel_input_raw.get(col, 0))
        if col in ["LODGOUT_COST", "ACTIVITY_COST", "TOTAL_COST"]:
            val *= 10000  # ë§Œì› ë‹¨ìœ„ â†’ ì› ë‹¨ìœ„
        input_vals.append(val)

    # 3. transform ì ìš©
    # scalerëŠ” ì´ë¯¸ fitë˜ì–´ ìˆì–´ì•¼ í•¨
    scaled_vals = scaler.transform([input_vals])[0]  # ê²°ê³¼: [0.23, 0.41, 0.37, 0.67] ë“±

    # 4. ë‹¤ì‹œ travel_inputì— ì €ì¥
    for i, col in enumerate(num_cols):
        travel_input[col] = scaled_vals[i]
    
    # ì´ë™ìˆ˜ë‹¨, ë‚˜ì´ëŒ€, ë™ë°˜ì
    travel_input['MVMN_NM_ENC'] = float(travel_input_raw.get('MVMN_NM_ENC', 0))
    travel_input['age_ENC'] = float(0) if int(user_json['AGE_GRP']) <= float(39) else 1.0

    mission_type = travel_input_raw.get('mission_type', 'normal')
    if mission_type == 'special':
        travel_input['whowith_ENC'] = float(7)
        # ëª¨ë“  PURPOSEë¥¼ 0ìœ¼ë¡œ ìœ ì§€
    else:
        whowith_label_to_index = {
            '3ëŒ€ ë™ë°˜ ì—¬í–‰': 0,
            '3ì¸ ì´ìƒ ì¹œêµ¬': 1,
            'ë‚˜í™€ë¡œ ì—¬í–‰': 2,
            'ë¶€ëª¨ ë™ë°˜': 3,
            'ë¶€ë¶€': 4,
            'ìë…€ë™ë°˜': 5,
            'ì»¤í”Œ': 6,
            'íŠ¹ë³„ë¯¸ì…˜': 7,
        }
        whowith_raw = travel_input_raw.get('whowith_ENC', 'ì»¤í”Œ')
        travel_input['whowith_ENC'] = float(whowith_label_to_index.get(whowith_raw, 0))

        # mission_ENC â†’ PURPOSE one-hot
        missions = travel_input_raw.get('mission_ENC', '')
        for code in missions.split(','):
            code = code.strip()
            if code.isdigit():
                key = f"PURPOSE_{code}"
                if key in travel_input:
                    travel_input[key] = 1.0

    # mission_ENC ì›ë˜ ì»¬ëŸ¼ë„ floatë¡œ ì¶”ê°€
    travel_input['mission_ENC'] = float(0) if mission_type == 'normal' and missions else 1.0

    
    user_df = pd.DataFrame([user_input]).reindex(columns=user_feature_keys, fill_value=0)
    travel_df = pd.DataFrame([travel_input]).reindex(columns=travel_feature_keys, fill_value=0)

    ################# CSV ì €ì¥ (ë””ë²„ê¹…ìš©) #################
    # user_df.to_csv('user_input.csv', index=False)
    # travel_df.to_csv('travel_input.csv', index=False)
    ####################################################

    return user_df, travel_df
